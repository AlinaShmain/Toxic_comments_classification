{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import word2vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Activation\n",
    "from keras.layers import concatenate, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import MaxPooling1D, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gaelic translation \\n\\nHi, don't suppose you c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hey dick \\nYou don't know what is copyright so...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"\\n\\nAm I correct in thinking that you are ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>== Notable Alumni == \\n\\n Why was this section...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have already been sent this message about va...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>== exuse me == \\n\\n i was not attacking someon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>:You're welcome, Vernon39! Thanks for your imp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Good point by JonC , legally the name of the s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>\"\\nNo such \"\"compromise\"\" was reached on Septe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>:::Again, we can't take the unverifiable claim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text  toxic  severe_toxic  \\\n",
       "0   0  Gaelic translation \\n\\nHi, don't suppose you c...      0             0   \n",
       "1   1  Hey dick \\nYou don't know what is copyright so...      1             0   \n",
       "2   2  \"\\n\\nAm I correct in thinking that you are ref...      0             0   \n",
       "3   3  == Notable Alumni == \\n\\n Why was this section...      0             0   \n",
       "4   4  I have already been sent this message about va...      1             0   \n",
       "5   5  == exuse me == \\n\\n i was not attacking someon...      0             0   \n",
       "6   6  :You're welcome, Vernon39! Thanks for your imp...      0             0   \n",
       "7   7  Good point by JonC , legally the name of the s...      0             0   \n",
       "8   8  \"\\nNo such \"\"compromise\"\" was reached on Septe...      0             0   \n",
       "9   9  :::Again, we can't take the unverifiable claim...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        1       0       1              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        1       0       1              0  \n",
       "5        0       0       0              0  \n",
       "6        0       0       0              0  \n",
       "7        0       0       0              0  \n",
       "8        0       0       0              0  \n",
       "9        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>Dmacks consitatnly edits other peoples pages a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150001</td>\n",
       "      <td>== Contested deletion == \\n\\n This article sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150002</td>\n",
       "      <td>March 2008\\n Please stop. If you continue to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150003</td>\n",
       "      <td>\"}\\n\\nAugust Esperanza Newsletter\\n{| style=\"\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150004</td>\n",
       "      <td>William Sledd\\n\\nOK, it is time We Tubers had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150005</td>\n",
       "      <td>\"\\n\\n Please apologize: you made a clear mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150006</td>\n",
       "      <td>What makes and egg crack? \\n FORCE!!!!!!!!! \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150007</td>\n",
       "      <td>\" \\n :::::No, your comparison is invalid. Your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150008</td>\n",
       "      <td>The Tree in a Test Tube, 1942 (full).ogv|The T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150009</td>\n",
       "      <td>:::I should have listened to your advice. Alan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                       comment_text\n",
       "0  150000  Dmacks consitatnly edits other peoples pages a...\n",
       "1  150001  == Contested deletion == \\n\\n This article sho...\n",
       "2  150002  March 2008\\n Please stop. If you continue to v...\n",
       "3  150003  \"}\\n\\nAugust Esperanza Newsletter\\n{| style=\"\"...\n",
       "4  150004  William Sledd\\n\\nOK, it is time We Tubers had ...\n",
       "5  150005  \"\\n\\n Please apologize: you made a clear mista...\n",
       "6  150006  What makes and egg crack? \\n FORCE!!!!!!!!! \\n...\n",
       "7  150007  \" \\n :::::No, your comparison is invalid. Your...\n",
       "8  150008  The Tree in a Test Tube, 1942 (full).ogv|The T...\n",
       "9  150009  :::I should have listened to your advice. Alan..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[target_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanImages(sentence):\n",
    "    cleanr = re.compile(r'\\w+\\.(jpg|png)')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanLinks(sentence):\n",
    "    cleanr = re.compile('((www\\.[^\\s]+)|(https?://[^\\s]+))')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile(r'\\|(.*?)\\r\\n')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_words(sentence):\n",
    "    repl = {\n",
    "        r'(I|i)\\'m': 'i am',\n",
    "        r'(\\w+)\\'re': '\\g<1> are',\n",
    "        r'(\\w+)\\'d': '\\g<1> would',\n",
    "        r'\\bwon\\'t\\b': 'will not',\n",
    "        r'(\\w+)n\\'t': '\\g<1> not',\n",
    "        r'\\bcannot\\b': 'can not',\n",
    "        r'(\\w+)\\'ll': '\\g<1> will',\n",
    "        r'(\\w+)\\'s': '\\g<1> is'\n",
    "    }\n",
    "\n",
    "    cleaned = str(sentence)\n",
    "    for i in repl.keys():\n",
    "        cleanr = re.compile(i)\n",
    "        cleaned = re.sub(cleanr, repl[i], cleaned)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStopWords(sentence):\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "    cleaned = re_stop_words.sub(\" \", str(sentence))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPunc(sentence):\n",
    "    to_exclude = string.punctuation + \"–\" + string.digits + \"—\" + \"•\"\n",
    "    cleaned = re.sub('[%s]' % re.escape(to_exclude), '', str(sentence))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSpaces(sentence):\n",
    "    clean = sentence.replace('\\n', ' ')\n",
    "    clean = clean.replace('\\t', ' ')\n",
    "    clean = clean.replace('\\r', ' ')\n",
    "    \n",
    "    clean = re.sub('\\s+', ' ', clean)\n",
    "    clean = re.sub('\\s+$', '', clean)\n",
    "        \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = text.str.lower()\n",
    "    text = text.apply(cleanHtml)\n",
    "    text = text.apply(cleanLinks)\n",
    "    text = text.apply(cleanImages)\n",
    "    text = text.apply(full_words)\n",
    "    text = text.apply(cleanStopWords)\n",
    "    text = text.apply(cleanPunc)\n",
    "    cleaned_text = text.apply(cleanSpaces)\n",
    "    \n",
    "    return cleaned_text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = cleanText(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(sentence):    \n",
    "    words = word_tokenize(sentence)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_comments = all_text.apply(text_to_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведение слов к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posTagging(sentence):\n",
    "    tagged = nltk.pos_tag(sentence)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'MD']\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizeComment(sentence): \n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    words = []\n",
    "    for word in sentence:\n",
    "        if is_adjective(word[1]):\n",
    "            words.append(wordnet_lemmatizer.lemmatize(word[0], pos=wn.ADJ))\n",
    "        elif is_noun(word[1]):\n",
    "            words.append(wordnet_lemmatizer.lemmatize(word[0], pos=wn.NOUN))\n",
    "        elif is_adverb(word[1]):\n",
    "            words.append(wordnet_lemmatizer.lemmatize(word[0], pos=wn.ADV))\n",
    "        elif is_verb(word[1]):\n",
    "            words.append(wordnet_lemmatizer.lemmatize(word[0], pos=wn.VERB))\n",
    "    return words      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    tagged_text = text.apply(posTagging)\n",
    "    lemmatized = tagged_text.apply(lemmatizeComment)\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_comments = lemmatize(tokenized_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [\" \".join(comment) for comment in tokenized_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_text = all_text[:len(train_text)]\n",
    "clean_test_text = all_text[len(train_text):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_comment_text'] = pd.Series(clean_train_text, index=train.index)\n",
    "train.to_csv('clean_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_comment_text'] = pd.Series(clean_test_text, index=test.index)\n",
    "test.to_csv('clean_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load clean comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pd.read_csv('clean_train.csv')\n",
    "train_text['clean_comment_text'] = train_text['clean_comment_text'].astype(str)\n",
    "\n",
    "test_text = pd.read_csv('clean_test.csv')\n",
    "test_text['clean_comment_text'] = test_text['clean_comment_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_text = train_text['clean_comment_text'].values\n",
    "clean_test_text = test_text['clean_comment_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gaelic translation hi suppose could help gaelic translation thanks advance able',\n",
       "       'hey dick know copyright shutup get write stupid bullshit talk page dhivehi language dhivehi language bullshit nonsese',\n",
       "       'correct think refer shatter vessel first discuss arizal mention might possible expand',\n",
       "       ...,\n",
       "       'see detail previous battle firs obviously seriously difficult history revenge block talk contribution',\n",
       "       'good idea sure great article end',\n",
       "       'princess irene duchess parma husband carlo hugo duke parma duchess parma article even mention title'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 1/2\n",
      "Word TFIDF 2/2\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "train_word_features = word_vectorizer.fit_transform(clean_train_text)\n",
    "print('Word TFIDF 1/2')\n",
    "test_word_features = word_vectorizer.transform(clean_test_text)\n",
    "print('Word TFIDF 2/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 6), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    ngram_range=(1, 6),\n",
    "    max_features=30000)\n",
    "char_vectorizer.fit(clean_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_features = char_vectorizer.transform(clean_train_text)\n",
    "test_char_features = char_vectorizer.transform(clean_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = hstack([train_char_features, train_word_features])\n",
    "test_features = hstack([test_char_features, test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('train_features.npz', train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('test_features.npz', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_word_features\n",
    "# del train_char_features\n",
    "\n",
    "# del test_word_features\n",
    "# del test_char_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = sparse.load_npz('train_features.npz')\n",
    "test_features = sparse.load_npz('test_features.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0.837216851023329\n",
      "severe_toxic\n",
      "0.6637535198426912\n",
      "obscene\n",
      "0.8604099854334917\n",
      "threat\n",
      "0.608337454571054\n",
      "insult\n",
      "0.8124256959914072\n",
      "identity_hate\n",
      "0.6903914701382333\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "avg_auc = 0\n",
    "for class_ in target_labels:\n",
    "    print(class_)\n",
    "    logreg = LogisticRegression(solver='sag', penalty='l2')\n",
    "    logreg.fit(train_features, y[class_])\n",
    "    models.append(logreg)\n",
    "    prediction = logreg.predict(train_features)\n",
    "    actual = y[class_]\n",
    "    AUC = roc_auc_score(actual,prediction)\n",
    "    print(AUC)\n",
    "    avg_auc = avg_auc + AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC = 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Mean AUC = {}'.format(np.round(float(avg_auc)/6.0,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "CV score for class toxic is 0.9400923548136658\n",
      "severe_toxic\n",
      "CV score for class severe_toxic is 0.9291451986192852\n",
      "obscene\n",
      "CV score for class obscene is 0.969619027585356\n",
      "threat\n",
      "CV score for class threat is 0.8374413089538898\n",
      "insult\n",
      "CV score for class insult is 0.9505633646203475\n",
      "identity_hate\n",
      "CV score for class identity_hate is 0.9112287530264432\n"
     ]
    }
   ],
   "source": [
    "modelsTrees = []\n",
    "losses = []\n",
    "for i, label in enumerate(target_labels):\n",
    "    print(label)\n",
    "    train_target = y[label]\n",
    "    classifier = ExtraTreesClassifier(n_estimators=30)\n",
    "    cv_loss = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV score for class {} is {}'.format(label, cv_loss))\n",
    "    classifier.fit(train_features, train_target)\n",
    "    modelsTrees.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(target_labels):\n",
    "    with open('models/trees/model_' + label + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsTrees[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = pd.DataFrame.from_dict({'id': test['id']})\n",
    "preds = np.zeros((len(test), len(target_labels)))\n",
    "submission = pd.concat([sub_ids, pd.DataFrame(preds, columns = target_labels)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(target_labels):\n",
    "    with open('models/trees/model_' + label + '.pkl', 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    \n",
    "    submission[label] = loaded_model.predict_proba(test_features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying LSA vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=1000)\n",
    "X_train_lsa = lsa.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lsa = lsa.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0.796306872495886\n",
      "severe_toxic\n",
      "0.6180355086776136\n",
      "obscene\n",
      "0.8292850122084928\n",
      "threat\n",
      "0.5724944781281074\n",
      "insult\n",
      "0.7708518451682986\n",
      "identity_hate\n",
      "0.6493205330488676\n"
     ]
    }
   ],
   "source": [
    "modelsLgR = []\n",
    "avg_auc = 0\n",
    "for class_ in target_labels:\n",
    "    print(class_)\n",
    "    logreg = LogisticRegression(solver='sag', penalty='l2')\n",
    "    logreg.fit(X_train_lsa, y[class_])\n",
    "    modelsLgR.append(logreg)\n",
    "    prediction = logreg.predict(X_train_lsa)\n",
    "    actual = y[class_]\n",
    "    AUC = roc_auc_score(actual,prediction)\n",
    "    print(AUC)\n",
    "    avg_auc = avg_auc + AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 200\n",
    "min_word_count = 1\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n",
    "downsampling = 1e-3\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_ = word2vec.Word2Vec(\n",
    "    sg = 1, seed = seed,\n",
    "    workers = num_workers,\n",
    "    size = num_features,\n",
    "    min_count = min_word_count,\n",
    "    window = context_size,\n",
    "    sample = downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_text = tokenized_comments[:len(train_text)]\n",
    "tokenized_test_text = tokenized_comments[len(train_text):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если загрузили очищенные комменты tokenized_train_text/tokenized_test_text не определены, поэтому\n",
    "# tokenized_train_text = train_text['clean_comment_text'].apply(text_to_words)\n",
    "# tokenized_test_text = test_text['clean_comment_text'].apply(text_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_.build_vocab(tokenized_train_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211442"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_.wv.vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461178910, 483992400)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_.train(tokenized_train_text, total_examples = word2vec_.corpus_count, epochs=100, compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_.save(\"comments_model.w2v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = word2vec.Word2Vec.load('comments_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None)\n",
    "\n",
    "tokenizer.fit_on_texts(clean_train_text)\n",
    "tokenized_train = tokenizer.texts_to_sequences(clean_train_text)\n",
    "tokenized_test = tokenizer.texts_to_sequences(clean_test_text)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 211442\n",
      "Longest comment size: 1250\n",
      "Average comment size: 32.231946666666666\n",
      "Stdev of comment size: 52.24658164968456\n",
      "Max comment size: 188\n"
     ]
    }
   ],
   "source": [
    "NUM = len(word_index)\n",
    "print('Vocab size: {}'.format(NUM))\n",
    "longest = max(len(seq) for seq in tokenized_train)\n",
    "print(\"Longest comment size: {}\".format(longest))\n",
    "average = np.mean([len(seq) for seq in tokenized_train])\n",
    "print(\"Average comment size: {}\".format(average))\n",
    "stdev = np.std([len(seq) for seq in tokenized_train])\n",
    "print(\"Stdev of comment size: {}\".format(stdev))\n",
    "SENTENCE_LENGTH = int(average + stdev * 3)\n",
    "print('Max comment size: {}'.format(SENTENCE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_train = pad_sequences(tokenized_train, maxlen=SENTENCE_LENGTH, padding='post', truncating='post')\n",
    "processed_X_test = pad_sequences(tokenized_test, maxlen=SENTENCE_LENGTH, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = w2v.vector_size \n",
    "\n",
    "embedding_matrix = np.zeros((NUM+1, DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= NUM:\n",
    "        break\n",
    "    if word in w2v.wv.vocab.keys():\n",
    "        embedding_matrix[i] = w2v.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(NUM+1, DIM, weights=[embedding_matrix], input_length=SENTENCE_LENGTH, trainable=True))\n",
    "\n",
    "model.add(LSTM(60, return_sequences=True, name='lstm_layer'))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, filepath, validation_data=(), interval=1, max_epoch = 100):\n",
    "        super(Callback, self).__init__()\n",
    "        print(\"After init\")\n",
    "        self.interval = interval\n",
    "        self.filepath = filepath\n",
    "        self.stopped_epoch = max_epoch\n",
    "        self.best = 0\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.y_pred = np.zeros(self.y_val.shape)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Epoch end 1\")\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_proba(self.X_val, verbose=0)\n",
    "            current = roc_auc_score(self.y_val, y_pred)\n",
    "            logs['roc_auc_val'] = current\n",
    "\n",
    "            if current > self.best:\n",
    "                print(\" - AUC - improved from {:.5f} to {:.5f}\".format(self.best, current))\n",
    "                self.best = current\n",
    "                self.y_pred = y_pred\n",
    "                self.stopped_epoch = epoch+1\n",
    "                self.model.save(self.filepath, overwrite=True)\n",
    "            else:\n",
    "                print(\" - AUC - did not improve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After init\n",
      "Train on 145500 samples, validate on 4500 samples\n",
      "Epoch 1/1\n",
      "145500/145500 [==============================] - 3052s 21ms/step - loss: 0.0760 - acc: 0.9716 - auc: 0.9161 - val_loss: 0.0546 - val_acc: 0.9783 - val_auc: 0.9588\n",
      "Epoch end 1\n",
      " - AUC - improved from 0.00000 to 0.97330\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy', auc])\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"roc_auc_val\", mode=\"max\", patience=2)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(processed_X_train, y, test_size = 0.03, random_state = 144)\n",
    "\n",
    "rocAuc = RocAucEvaluation(filepath='models/lstm/model.best.hdf5', validation_data=(x_test, y_test), interval=1)\n",
    "hist_adam = model.fit(x_train, y_train, batch_size=64, epochs=1, validation_data=(x_test, y_test),\n",
    "         callbacks=[rocAuc, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(processed_X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = pd.DataFrame.from_dict({'id': test['id']})\n",
    "preds = np.zeros((len(test), len(target_labels)))\n",
    "submission = pd.concat([sub_ids, pd.DataFrame(preds, columns = target_labels)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 6):\n",
    "    submission[target_labels[i]] = predictions[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(NUM + 1, DIM, weights=[embedding_matrix], input_length=SENTENCE_LENGTH, trainable=True))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After init\n",
      "Train on 145500 samples, validate on 4500 samples\n",
      "Epoch 1/1\n",
      "145500/145500 [==============================] - 3195s 22ms/step - loss: 0.0624 - acc: 0.9769 - auc: 0.9526 - val_loss: 0.0492 - val_acc: 0.9813 - val_auc: 0.9695\n",
      "Epoch end 1\n",
      " - AUC - improved from 0.00000 to 0.97837\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', auc])\n",
    "\n",
    "rocAuc = RocAucEvaluation(filepath='models/cnn/model.best.hdf5', validation_data=(x_test, y_test), interval=1)\n",
    "hist_adam = model.fit(x_train, y_train, batch_size=64, epochs=1, validation_data=(x_test, y_test),\n",
    "         callbacks=[rocAuc, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(processed_X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = pd.DataFrame.from_dict({'id': test['id']})\n",
    "preds = np.zeros((len(test), len(target_labels)))\n",
    "submission = pd.concat([sub_ids, pd.DataFrame(preds, columns = target_labels)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 6):\n",
    "    submission[target_labels[i]] = predictions[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "    if nwords == 0:\n",
    "        nwords = 1\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    reviewFeatureVecs = np.zeros((len(reviews), num_features), dtype=\"float32\")\n",
    "    counter = 0\n",
    "    for review in reviews:\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_text = tokenized_comments[:len(train_text)]\n",
    "tokenized_test_text = tokenized_comments[len(train_text):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alina\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "f_matrix_train = getAvgFeatureVecs(tokenized_train_text, w2v, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = pd.DataFrame(f_matrix_train)\n",
    "matrix_train.to_csv('f_matrix_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alina\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "f_matrix_test = getAvgFeatureVecs(tokenized_test_text, w2v, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_test = pd.DataFrame(f_matrix_test)\n",
    "matrix_test.to_csv('f_matrix_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_matrix_train = pd.read_csv('f_matrix_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_matrix_train = np.array(f_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "modelsMLP = []\n",
    "for i in range(0, 6):\n",
    "    m = MLPClassifier(solver='adam', hidden_layer_sizes=(30,30,30), random_state=1)\n",
    "    modelsMLP.append(m)\n",
    "print(modelsMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alina\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y[0]\n",
    "print('...Processing {}'.format(target_labels[0]))\n",
    "modelsMLP[0].fit(f_matrix_train, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9288817567184795\n"
     ]
    }
   ],
   "source": [
    "predictions = modelsMLP[0].predict(f_matrix_train)\n",
    "print(\"Accuracy = \", roc_auc_score(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/mlp/model_' + target_labels[0] + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsMLP[0], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing severe_toxic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y[1]\n",
    "print('...Processing {}'.format(target_labels[1]))\n",
    "modelsMLP[1].fit(f_matrix_train, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/mlp/model_' + target_labels[1] + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsMLP[1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9448461525625697\n"
     ]
    }
   ],
   "source": [
    "predictions = modelsMLP[1].predict(f_matrix_train)\n",
    "print(\"Accuracy = \", roc_auc_score(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[target_labels[1]] = modelsMLP[1].predict_proba(f_matrix_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing obscene\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y[2]\n",
    "print('...Processing {}'.format(target_labels[2]))\n",
    "modelsMLP[2].fit(f_matrix_train, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/mlp/model_' + target_labels[2] + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsMLP[2], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9748833856975384\n"
     ]
    }
   ],
   "source": [
    "predictions = modelsMLP[2].predict(f_matrix_train)\n",
    "print(\"Accuracy = \", roc_auc_score(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing threat\n"
     ]
    }
   ],
   "source": [
    "y_true = y[3]\n",
    "print('...Processing {}'.format(target_labels[3]))\n",
    "modelsMLP[3].fit(f_matrix_train, y_true)\n",
    "\n",
    "with open('models/mlp/model_' + target_labels[3] + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsMLP[3], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9872981986817906\n"
     ]
    }
   ],
   "source": [
    "predictions = modelsMLP[3].predict(f_matrix_train)\n",
    "print(\"Accuracy = \", roc_auc_score(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing insult\n"
     ]
    }
   ],
   "source": [
    "y_true = y[4]\n",
    "print('...Processing {}'.format(target_labels[4]))\n",
    "modelsMLP[4].fit(f_matrix_train, y_true)\n",
    "\n",
    "with open('models/mlp/model_' + target_labels[4] + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsMLP[4], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9396339576048516\n"
     ]
    }
   ],
   "source": [
    "predictions = modelsMLP[4].predict(f_matrix_train)\n",
    "print(\"Accuracy = \", roc_auc_score(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing identity_hate\n"
     ]
    }
   ],
   "source": [
    "y_true = y[5]\n",
    "print('...Processing {}'.format(target_labels[5]))\n",
    "modelsMLP[5].fit(f_matrix_train, y_true)\n",
    "\n",
    "with open('models/mlp/model_' + target_labels[5] + '.pkl', 'wb') as f:\n",
    "                pickle.dump(modelsMLP[5], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9846426212979155\n"
     ]
    }
   ],
   "source": [
    "predictions = modelsMLP[5].predict(f_matrix_train)\n",
    "print(\"Accuracy = \", roc_auc_score(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = pd.DataFrame.from_dict({'id': test['id']})\n",
    "preds = np.zeros((len(test), len(target_labels)))\n",
    "submission = pd.concat([sub_ids, pd.DataFrame(preds, columns = target_labels)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 6):\n",
    "    with open('models/mlp/model_' + target_labels[i] + '.pkl', 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    \n",
    "    submission[target_labels[i]] = loaded_model.predict_proba(f_matrix_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>8.907590e-16</td>\n",
       "      <td>2.412191e-02</td>\n",
       "      <td>5.291121e-32</td>\n",
       "      <td>5.717639e-01</td>\n",
       "      <td>1.400704e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.531597e-20</td>\n",
       "      <td>6.220660e-14</td>\n",
       "      <td>1.604982e-11</td>\n",
       "      <td>2.036368e-06</td>\n",
       "      <td>1.424178e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150002</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>3.566068e-15</td>\n",
       "      <td>1.639609e-27</td>\n",
       "      <td>1.121994e-12</td>\n",
       "      <td>5.423424e-09</td>\n",
       "      <td>1.099360e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150003</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>8.993397e-16</td>\n",
       "      <td>1.203725e-08</td>\n",
       "      <td>1.251981e-28</td>\n",
       "      <td>4.773208e-11</td>\n",
       "      <td>1.976781e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150004</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>1.058188e-18</td>\n",
       "      <td>3.846464e-06</td>\n",
       "      <td>1.821899e-23</td>\n",
       "      <td>3.793919e-07</td>\n",
       "      <td>3.710725e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150005</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>2.398821e-21</td>\n",
       "      <td>9.335110e-09</td>\n",
       "      <td>3.107786e-36</td>\n",
       "      <td>6.483433e-06</td>\n",
       "      <td>1.569068e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150006</td>\n",
       "      <td>0.997307</td>\n",
       "      <td>1.804892e-04</td>\n",
       "      <td>7.921221e-01</td>\n",
       "      <td>2.240715e-10</td>\n",
       "      <td>6.105005e-01</td>\n",
       "      <td>1.196878e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150007</td>\n",
       "      <td>0.202951</td>\n",
       "      <td>2.663867e-08</td>\n",
       "      <td>7.247397e-03</td>\n",
       "      <td>2.643507e-14</td>\n",
       "      <td>5.291487e-03</td>\n",
       "      <td>3.543002e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150008</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>2.912806e-33</td>\n",
       "      <td>2.602724e-08</td>\n",
       "      <td>5.834317e-30</td>\n",
       "      <td>8.980805e-23</td>\n",
       "      <td>1.927979e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150009</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>1.600293e-10</td>\n",
       "      <td>1.914783e-07</td>\n",
       "      <td>3.821856e-10</td>\n",
       "      <td>3.654804e-04</td>\n",
       "      <td>5.203025e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     toxic  severe_toxic       obscene        threat        insult  \\\n",
       "0  150000  0.964798  8.907590e-16  2.412191e-02  5.291121e-32  5.717639e-01   \n",
       "1  150001  0.000006  2.531597e-20  6.220660e-14  1.604982e-11  2.036368e-06   \n",
       "2  150002  0.000028  3.566068e-15  1.639609e-27  1.121994e-12  5.423424e-09   \n",
       "3  150003  0.002818  8.993397e-16  1.203725e-08  1.251981e-28  4.773208e-11   \n",
       "4  150004  0.007929  1.058188e-18  3.846464e-06  1.821899e-23  3.793919e-07   \n",
       "5  150005  0.002642  2.398821e-21  9.335110e-09  3.107786e-36  6.483433e-06   \n",
       "6  150006  0.997307  1.804892e-04  7.921221e-01  2.240715e-10  6.105005e-01   \n",
       "7  150007  0.202951  2.663867e-08  7.247397e-03  2.643507e-14  5.291487e-03   \n",
       "8  150008  0.000044  2.912806e-33  2.602724e-08  5.834317e-30  8.980805e-23   \n",
       "9  150009  0.049743  1.600293e-10  1.914783e-07  3.821856e-10  3.654804e-04   \n",
       "\n",
       "   identity_hate  \n",
       "0   1.400704e-23  \n",
       "1   1.424178e-16  \n",
       "2   1.099360e-17  \n",
       "3   1.976781e-17  \n",
       "4   3.710725e-15  \n",
       "5   1.569068e-15  \n",
       "6   1.196878e-08  \n",
       "7   3.543002e-10  \n",
       "8   1.927979e-47  \n",
       "9   5.203025e-18  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"submission.csv\")\n",
    "sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
